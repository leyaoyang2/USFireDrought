{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "## Imports ##\n",
    "#############\n",
    "\n",
    "# General Use / Computation Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:34<00:00, 11.83s/it]\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## Reading the Data ##\n",
    "######################\n",
    "incidents_full = pd.DataFrame() # Define full DataFrame as empty df\n",
    "fires_full = pd.DataFrame() # Define full DataFrame as empty df\n",
    "addresses_full = pd.DataFrame() # Define full DataFrame as empty df\n",
    "incidents_cols = ['STATE', 'FDID', 'INC_DATE', 'INC_NO', 'EXP_NO', 'INC_TYPE']\n",
    "fires_cols = ['STATE', 'FDID', 'INC_DATE', 'INC_NO', 'EXP_NO', 'AREA_ORIG', 'FIRST_IGN', 'CAUSE_IGN']\n",
    "addresses_cols = ['STATE', 'FDID', 'INC_DATE', 'INC_NO', 'EXP_NO', 'CITY', 'STATE_ID', 'ZIP5']\n",
    "\n",
    "for year in tqdm(np.arange(2004, 2019)): # Loop through the years (with progress bar)\n",
    "    os.chdir('./NFIRS_DATA_RAW/{}'.format('{} data'.format(year))) # Change directory to the folder where the data is stored\n",
    "    if year<2012:\n",
    "        incidents = pd.read_csv( # Read the basicincident file, separated by ^\n",
    "            'basicincident.csv',\n",
    "            usecols = incidents_cols,\n",
    "            encoding = 'latin-1',\n",
    "            low_memory = False\n",
    "        )\n",
    "        #incidents['INC_DATE'] = [datetime.strptime(str(date), '%m%d%Y') for date in incidents['INC_DATE']] ## Format date as Datetime object\n",
    "        fires = pd.read_csv( # Read the fireincident file, separated by ^\n",
    "            'fireincident.csv',\n",
    "            usecols = fires_cols,\n",
    "            encoding = 'latin-1',\n",
    "            low_memory = False\n",
    "        )\n",
    "        addresses = pd.read_csv( # Read the incidentaddress file, separated by ^\n",
    "            'incidentaddress.csv',\n",
    "            usecols = addresses_cols,\n",
    "            encoding = 'latin-1',\n",
    "            low_memory = False\n",
    "        )\n",
    "    else:\n",
    "        incidents = pd.read_csv( # Read the basicincident file, separated by ^\n",
    "            'basicincident.txt',\n",
    "            usecols = incidents_cols,\n",
    "            delimiter = '^',\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            low_memory = False\n",
    "        )\n",
    "        fires = pd.read_csv( # Read the fireincident file, separated by ^\n",
    "            'fireincident.txt',\n",
    "            usecols = fires_cols,\n",
    "            delimiter = '^',\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            low_memory = False\n",
    "        )\n",
    "        addresses = pd.read_csv( # Read the incidentaddress file, separated by ^\n",
    "            'incidentaddress.txt',\n",
    "            usecols = addresses_cols,\n",
    "            delimiter = '^',\n",
    "            encoding=\"ISO-8859-1\",\n",
    "            low_memory = False\n",
    "        )\n",
    "    if len(incidents_full) == 0:\n",
    "        incidents_full = incidents\n",
    "    else:\n",
    "        incidents_full = incidents_full.append(incidents) ## append each year to the full DataFrame\n",
    "    if len(fires_full) == 0:\n",
    "        fires_full = fires\n",
    "    else:\n",
    "        fires_full = fires_full.append(fires) ## append each year to the full DataFrame\n",
    "    if len(addresses_full) == 0:\n",
    "        addresses_full = addresses\n",
    "    else:\n",
    "        addresses_full = addresses_full.append(addresses) ## append each year to the full DataFrame\n",
    "    os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values (Incidents):\n",
      "STATE: 3693\n",
      "FDID: 0\n",
      "INC_DATE: 0\n",
      "INC_NO: 0\n",
      "EXP_NO: 0\n",
      "Number of Missing Values (Fires):\n",
      "STATE: 1125\n",
      "FDID: 0\n",
      "INC_DATE: 0\n",
      "INC_NO: 0\n",
      "EXP_NO: 0\n"
     ]
    }
   ],
   "source": [
    "# The unique identifier for these incident-associated records is the combination of the State, \n",
    "# fire department ID, incident date, incident number, and exposure number (STATE, FDID, INC_DATE, INC_NO, and EXP_NO)\n",
    "# NFIRS Version 5.0 Fire Data Analysis Guidelines and Issues Page 8\n",
    "# https://www.usfa.fema.gov/downloads/pdf/nfirs/nfirs_data_analysis_guidelines_issues.pdf\n",
    "id_cols = ['STATE', 'FDID', 'INC_DATE', 'INC_NO', 'EXP_NO']\n",
    "print('Number of Missing Values (Incidents):')\n",
    "for col in id_cols:\n",
    "     print('{}: {}'.format(col, incidents_full[col].isna().sum()))\n",
    "print('Number of Missing Values (Fires):')\n",
    "for col in id_cols:\n",
    "     print('{}: {}'.format(col, fires_full[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>FDID</th>\n",
       "      <th>INC_DATE</th>\n",
       "      <th>INC_NO</th>\n",
       "      <th>EXP_NO</th>\n",
       "      <th>AREA_ORIG</th>\n",
       "      <th>FIRST_IGN</th>\n",
       "      <th>CAUSE_IGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>11100</td>\n",
       "      <td>1022004</td>\n",
       "      <td>0400156</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>62</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>11100</td>\n",
       "      <td>1032004</td>\n",
       "      <td>0400311</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>11100</td>\n",
       "      <td>1072004</td>\n",
       "      <td>0400733</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>11100</td>\n",
       "      <td>1152004</td>\n",
       "      <td>0401759</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>11100</td>\n",
       "      <td>1212004</td>\n",
       "      <td>0402449</td>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE   FDID  INC_DATE   INC_NO  EXP_NO AREA_ORIG FIRST_IGN CAUSE_IGN\n",
       "0    AK  11100   1022004  0400156       0        83        62         U\n",
       "1    AK  11100   1032004  0400311       0        21        94         2\n",
       "2    AK  11100   1072004  0400733       0        00        81         2\n",
       "3    AK  11100   1152004  0401759       0        81        81         3\n",
       "4    AK  11100   1212004  0402449       0        09        88         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## Filling NaNs, Creating a Unique ID ##\n",
    "## Not all years have INCIDENT_KEY    ##\n",
    "########################################\n",
    "\n",
    "## Fill NaN for important categories; impute with 'UNKNOWN' ##\n",
    "incidents_full.fillna(\n",
    "    {\n",
    "        'STATE': 'UNKNOWN',\n",
    "        'INC_NO': 'UNKNOWN',\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "fires_full.fillna(\n",
    "    {\n",
    "        'STATE': 'UNKNOWN',\n",
    "        'INC_NO': 'UNKNOWN',\n",
    "        'AREA_ORIG': 'UNKNOWN',\n",
    "        'FIRST_IGN': 'UNKNOWN'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "def str2(x): ## put all addresses in uppercase and remove NaN missing values\n",
    "    if str(x) == 'nan':\n",
    "        return ''\n",
    "    else:\n",
    "        return str(x).upper()\n",
    "\n",
    "## Create unique id ##\n",
    "incidents_full['id'] = ['_'.join([str2(a), str2(b), str2(c), str2(d), str2(e)]) for a, b, c, d, e in zip(\n",
    "    incidents_full['STATE'],\n",
    "    incidents_full['FDID'],\n",
    "    incidents_full['INC_DATE'],\n",
    "    incidents_full['INC_NO'],\n",
    "    incidents_full['EXP_NO']\n",
    "    )]\n",
    "fires_full['id'] = ['_'.join([str2(a), str2(b), str2(c), str2(d), str2(e)]) for a, b, c, d, e in zip(\n",
    "    fires_full['STATE'],\n",
    "    fires_full['FDID'],\n",
    "    fires_full['INC_DATE'],\n",
    "    fires_full['INC_NO'],\n",
    "    fires_full['EXP_NO']\n",
    "    )]\n",
    "addresses_full['id'] = ['_'.join([str2(a), str2(b), str2(c), str2(d), str2(e)]) for a, b, c, d, e in zip(\n",
    "    addresses_full['STATE'],\n",
    "    addresses_full['FDID'],\n",
    "    addresses_full['INC_DATE'],\n",
    "    addresses_full['INC_NO'],\n",
    "    addresses_full['EXP_NO']\n",
    "    )]\n",
    "# addresses_full['address'] = [re.sub(' +', ' ', ' '.join([str2(a), str2(b), str2(c), str2(d), str2(e), str2(f), str2(g), str2(h), str2(i)])) ## get rid of extra spaces\n",
    "# for a, b, c, d, e, f, g, h, i in zip(\n",
    "#     addresses_full['NUM_MILE'],\n",
    "#     addresses_full['STREET_PRE'],\n",
    "#     addresses_full['STREETNAME'],\n",
    "#     addresses_full['STREETTYPE'],\n",
    "#     addresses_full['STREETSUF'],\n",
    "#     addresses_full['APT_NO'],\n",
    "#     addresses_full['CITY'],\n",
    "#     addresses_full['STATE_ID'],\n",
    "#     addresses_full['ZIP5'],\n",
    "# )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped Duplicates (Incidents)\n",
      "Database number of entries: 16867269\n",
      "Number of Unique IDs: 16867269\n",
      "Dropped Duplicates (Fires)\n",
      "Database number of entries: 5007834\n",
      "Number of Unique IDs: 5007834\n",
      "Dropped Duplicates (Addresses)\n",
      "Database number of entries: 16867269\n",
      "Number of Unique IDs: 16867269\n"
     ]
    }
   ],
   "source": [
    "# Drop Duplicates for all 3 DataFrames #\n",
    "incidents_full.drop_duplicates('id', inplace=True)\n",
    "print('Dropped Duplicates (Incidents)')\n",
    "print('Database number of entries: {}\\nNumber of Unique IDs: {}'.format(len(incidents_full), incidents_full['id'].nunique()))\n",
    "\n",
    "fires_full.drop_duplicates('id', inplace=True)\n",
    "print('Dropped Duplicates (Fires)')\n",
    "print('Database number of entries: {}\\nNumber of Unique IDs: {}'.format(len(fires_full), fires_full['id'].nunique()))\n",
    "\n",
    "addresses_full.drop_duplicates('id', inplace=True)\n",
    "print('Dropped Duplicates (Addresses)')\n",
    "print('Database number of entries: {}\\nNumber of Unique IDs: {}'.format(len(addresses_full), addresses_full['id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_full = incidents_full[[ # filter to use only the relevant columns for merging\n",
    "    'id',\n",
    "    'INC_TYPE',\n",
    "]]\n",
    "fires_full = fires_full[[ # filter to use only the relevant columns for merging\n",
    "    'id',\n",
    "    'AREA_ORIG',\n",
    "    'FIRST_IGN',\n",
    "    'CAUSE_IGN'\n",
    "]]\n",
    "addresses_full = addresses_full[[ # filter to use only the relevant columns for merging\n",
    "    'id',\n",
    "    'INC_DATE',\n",
    "    'FDID',\n",
    "    'CITY',\n",
    "    'STATE',\n",
    "    'ZIP5'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires_merged = fires_full.merge( # merge the fires, incidents and addresses together\n",
    "    incidents_full,\n",
    "    how = 'left',\n",
    "    left_on = 'id',\n",
    "    right_on = 'id'\n",
    ").merge(\n",
    "    addresses_full,\n",
    "    how = 'left',\n",
    "    left_on = 'id',\n",
    "    right_on = 'id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions for a wildfire #\n",
    "# INC_TYPE\n",
    "# 140 Natural vegetation fire, other.\n",
    "# 141 Forest, woods or wildland fire.\n",
    "# 142 Brush or brush-and-grass mixture fire.\n",
    "# 143 Grass fire.\n",
    "\n",
    "# AREA_ORIG\n",
    "# 94 Open area - outside; included are farmland, field.\n",
    "# 95 Wildland, woods.\n",
    "\n",
    "\n",
    "# FIRST_IGN\n",
    "# 71 Agricultural crop, including fruits and vegetables.\n",
    "# 72 Light vegetation - not crop, including grass.\n",
    "# 73 Heavy vegetation - not crop, including trees.\n",
    "\n",
    "# CAUSE_IGN\n",
    "# 4 Act of nature.\n",
    "# 2 Unintentional.\n",
    "\n",
    "wildfires = fires_merged[\n",
    "    (fires_merged['INC_TYPE'].isin(['140', '141', '142', '143'])) |\n",
    "    ((fires_merged['AREA_ORIG'].isin(['94', '95'])) & (fires_merged['FIRST_IGN'].isin(['71', '72', '73'])))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>AREA_ORIG</th>\n",
       "      <th>FIRST_IGN</th>\n",
       "      <th>CAUSE_IGN</th>\n",
       "      <th>INC_TYPE</th>\n",
       "      <th>INC_DATE</th>\n",
       "      <th>FDID</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ZIP5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>AK_13000_5182004_0000468_0</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>U</td>\n",
       "      <td>142</td>\n",
       "      <td>5182004.0</td>\n",
       "      <td>13000</td>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>AK</td>\n",
       "      <td>99901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AK_13000_6212004_0000634_0</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>6212004.0</td>\n",
       "      <td>13000</td>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>AK</td>\n",
       "      <td>99901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>AK_13425_2272004_0000011_0</td>\n",
       "      <td>95</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2272004.0</td>\n",
       "      <td>13425</td>\n",
       "      <td>Ketchikan</td>\n",
       "      <td>AK</td>\n",
       "      <td>99901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>AK_17250_7132004_0000001_0</td>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>7132004.0</td>\n",
       "      <td>17250</td>\n",
       "      <td>ANGOON</td>\n",
       "      <td>AK</td>\n",
       "      <td>99820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>AK_23100_5012004_0009682_0</td>\n",
       "      <td>94</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5012004.0</td>\n",
       "      <td>23100</td>\n",
       "      <td>Anchorage Bowl</td>\n",
       "      <td>AK</td>\n",
       "      <td>99516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id AREA_ORIG FIRST_IGN CAUSE_IGN  INC_TYPE  \\\n",
       "78   AK_13000_5182004_0000468_0        95        72         U       142   \n",
       "80   AK_13000_6212004_0000634_0        95        72         1       142   \n",
       "108  AK_13425_2272004_0000011_0        95        73         2       100   \n",
       "155  AK_17250_7132004_0000001_0        94        72         2       141   \n",
       "322  AK_23100_5012004_0009682_0        94        72         1       151   \n",
       "\n",
       "      INC_DATE   FDID            CITY STATE   ZIP5  \n",
       "78   5182004.0  13000       Ketchikan    AK  99901  \n",
       "80   6212004.0  13000       Ketchikan    AK  99901  \n",
       "108  2272004.0  13425       Ketchikan    AK  99901  \n",
       "155  7132004.0  17250          ANGOON    AK  99820  \n",
       "322  5012004.0  23100  Anchorage Bowl    AK  99516  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wildfires = wildfires[~(wildfires['CAUSE_IGN'].isin(['1', '3']))]\n",
    "wildfires.head()\n",
    "wildfires.to_csv('wildfires.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b868310b69bc70cb182f8bc140c1d0ace68fba83ff424a9f4f95651e0db85a5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
